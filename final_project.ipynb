{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6895fd34-b554-4650-81a0-755062a3c018",
   "metadata": {},
   "source": [
    "## Nadav Mashiach\n",
    "## Amit Stein\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcd177d-2fdf-4c4a-b94e-5ed9ae432c0c",
   "metadata": {},
   "source": [
    "## Import Statements for Data Preparation and Elastic Net Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdf043ea-4d49-4b51-acfd-0044cd058120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b25ddc-e814-400d-bdec-c8945f788be5",
   "metadata": {},
   "source": [
    "## Prepare the data, clean and parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8614976-3e27-4197-af11-c162a129f0a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def prepare_data(raw_df, target='Price'):\n",
    "    df = raw_df.copy()\n",
    "\n",
    "    def clean_numeric(x):\n",
    "        \"\"\"Cleans numeric values in a DataFrame column.\"\"\"\n",
    "        if isinstance(x, str):\n",
    "            return pd.to_numeric(x.replace(',', ''), errors='coerce')\n",
    "        return x\n",
    "\n",
    "    def clean_and_impute_numeric_columns(df, numeric_columns):\n",
    "        \"\"\"Cleans and imputes numeric columns.\"\"\"\n",
    "        for col in numeric_columns:\n",
    "            df[col] = df[col].apply(clean_numeric)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "        return df\n",
    "    \n",
    "    def remove_manufactor_from_model(df):\n",
    "        \"\"\"Removes the manufactor name from the model column.\"\"\"\n",
    "        df['model'] = df.apply(lambda x: x['model'].replace(x['manufactor'], '').strip() if pd.notna(x['model']) and pd.notna(x['manufactor']) else x['model'], axis=1)\n",
    "        return df\n",
    "    \n",
    "    def impute_categorical_columns(df):\n",
    "        \"\"\"Imputes categorical columns with a constant value.\"\"\"\n",
    "        categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "        categorical_imputer = SimpleImputer(strategy='constant', fill_value='Unknown')\n",
    "        df[categorical_columns] = categorical_imputer.fit_transform(df[categorical_columns])\n",
    "        return df\n",
    "\n",
    "    def convert_date_columns(df, date_columns):\n",
    "        \"\"\"Converts specified columns to datetime.\"\"\"\n",
    "        for col in date_columns:\n",
    "            df[col] = pd.to_datetime(df[col], format='%d/%m/%Y', errors='coerce')\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def remove_outliers(df, column):\n",
    "        \"\"\"Removes outliers from a specified numeric column using the IQR method.\"\"\"\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    \n",
    "    \n",
    "    def create_season_column(df, date_column):\n",
    "        \"\"\"Creates a season column based on the month of a date column.\"\"\"\n",
    "        df['Season'] = df[date_column].dt.month.map({\n",
    "            12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
    "            3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "            6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
    "            9: 'Fall', 10: 'Fall', 11: 'Fall'\n",
    "        }).fillna('Unknown')\n",
    "        return df\n",
    "    \n",
    "    def create_model_manufactor_feature(df):\n",
    "        df['Model_Manufactor'] = df['model'].astype(str) + '_' + df['manufactor'].astype(str)\n",
    "        return df    \n",
    "    \n",
    "    def create_derived_features(df):\n",
    "        \"\"\"Creates derived features such as Age, Km_per_year, and Age_Hand_interaction.\"\"\"\n",
    "        current_year = pd.Timestamp.now().year\n",
    "        df['Age'] = current_year - df['Year']\n",
    "        df['Age_Hand_interaction'] = df['Age'] * df['Hand']\n",
    "        return df\n",
    "\n",
    "    def drop_unnecessary_columns(df, columns_to_drop):\n",
    "        \"\"\"Drops unnecessary columns from the DataFrame.\"\"\"\n",
    "        return df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "    # Define numeric columns\n",
    "    numeric_columns = ['capacity_Engine', 'Km', 'Pic_num', 'Year', 'Hand', target]\n",
    "\n",
    "    # Clean and impute numeric columns\n",
    "    df = clean_and_impute_numeric_columns(df, numeric_columns)\n",
    "\n",
    "    # Impute categorical columns\n",
    "    df = impute_categorical_columns(df)\n",
    "    \n",
    "     # Remove outliers for 'Year'\n",
    "    df = remove_outliers(df, 'Year')\n",
    "    \n",
    "     # Remove manufactor from model\n",
    "    df = remove_manufactor_from_model(df)\n",
    "\n",
    "    df = create_model_manufactor_feature(df)\n",
    "    \n",
    "    # Convert date columns\n",
    "    date_columns = ['Cre_date', 'Repub_date']\n",
    "    df = convert_date_columns(df, date_columns)\n",
    "\n",
    "    # Create season column\n",
    "    df = create_season_column(df, 'Cre_date')\n",
    "    \n",
    "    # Create derived features\n",
    "    df = create_derived_features(df)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = ['Cre_date', 'Repub_date', 'Description', 'Supply_score', 'Test']\n",
    "    df = drop_unnecessary_columns(df, columns_to_drop)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbecb15d-e2af-4963-b879-7d642b32e292",
   "metadata": {},
   "source": [
    "#### Key Points:\n",
    "\n",
    "1. **Data Cleaning and Imputation Functions**\n",
    "    - **`def clean_numeric`**: This function is used to clean numeric data by removing non-numeric characters and converting them to numeric types.\n",
    "    - **`def clean_and_impute_numeric_columns`**: This function cleans and imputes numeric columns by filling missing values with the median value of each column.\n",
    "    - **`def impute_categorical_columns`**: This function imputes missing values in categorical columns with a constant value, 'Unknown', ensuring no missing values remain.\n",
    "    - **`def remove_outliers`**: This function is used to remove outliers from a specified numeric column in a DataFrame using the Interquartile Range (IQR) method. The IQR method identifies outliers by calculating the range within which the middle 50% of the data lie (between the first and third quartiles) and then excluding data points that fall outside of 1.5 times this range. In this context, it was used specifically to remove outliers from the 'Year' column..\n",
    "\n",
    "\n",
    "2. **Date Conversion and Season Column Creation**\n",
    "    - **`def convert_date_columns`**: This function standardizes date formats to ensure consistency across the dataset. It addresses issues where date values may be in different formats.\n",
    "    - **`def create_season_column`**: Recognizing that the original `Cre_date` column was not contributing effectively to the model, this function creates a new 'Season' column based on the month extracted from `Cre_date`.\n",
    "\n",
    "3. **Derived Feature Creation**\n",
    "    - **`def create_derived_features`**: Through analysis, we identified key columns that significantly impact the model's performance. This function creates new features based on these important columns, enhancing the model's predictive power.\n",
    "\n",
    "4. **Dropping Unnecessary Columns**\n",
    "    - **`def drop_unnecessary_columns`**: Based on the model's performance results and prior knowledge, this function removes columns that are deemed unnecessary. This step is crucial for improving the model's efficiency and reducing its complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82695d04-cc34-45ab-a793-ce4247055b14",
   "metadata": {},
   "source": [
    "## Load the dataframe, and prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23012bc8-09cb-48f9-a424-b70a5b2d4f2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1485, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "raw_url = 'https://raw.githubusercontent.com/nadav52/Matala-2/main/dataset.csv'\n",
    "df = pd.read_csv(raw_url, engine='python')\n",
    "\n",
    "# Prepare data\n",
    "prepared_df = prepare_data(df)\n",
    "\n",
    "prepared_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de2576d-7180-4967-aac2-3cb0d9bd1571",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manufactor</th>\n",
       "      <th>Year</th>\n",
       "      <th>model</th>\n",
       "      <th>Hand</th>\n",
       "      <th>Gear</th>\n",
       "      <th>capacity_Engine</th>\n",
       "      <th>Engine_type</th>\n",
       "      <th>Prev_ownership</th>\n",
       "      <th>Curr_ownership</th>\n",
       "      <th>Area</th>\n",
       "      <th>City</th>\n",
       "      <th>Price</th>\n",
       "      <th>Pic_num</th>\n",
       "      <th>Color</th>\n",
       "      <th>Km</th>\n",
       "      <th>Model_Manufactor</th>\n",
       "      <th>Season</th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Hand_interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>יונדאי</td>\n",
       "      <td>2015</td>\n",
       "      <td>i35</td>\n",
       "      <td>2</td>\n",
       "      <td>אוטומטית</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>בנזין</td>\n",
       "      <td>פרטית</td>\n",
       "      <td>פרטית</td>\n",
       "      <td>רעננה - כפר סבא</td>\n",
       "      <td>רעננה</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>כחול כהה מטאלי</td>\n",
       "      <td>144000.0</td>\n",
       "      <td>i35_יונדאי</td>\n",
       "      <td>Summer</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ניסאן</td>\n",
       "      <td>2018</td>\n",
       "      <td>מיקרה</td>\n",
       "      <td>1</td>\n",
       "      <td>אוטומטית</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>בנזין</td>\n",
       "      <td>פרטית</td>\n",
       "      <td>פרטית</td>\n",
       "      <td>מושבים בשרון</td>\n",
       "      <td>אבן יהודה</td>\n",
       "      <td>49000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>כחול בהיר</td>\n",
       "      <td>69000.0</td>\n",
       "      <td>מיקרה_ניסאן</td>\n",
       "      <td>Spring</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>סוזוקי</td>\n",
       "      <td>2010</td>\n",
       "      <td>סוויפט</td>\n",
       "      <td>1</td>\n",
       "      <td>אוטומטית</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>בנזין</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>רמת</td>\n",
       "      <td>רמת</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>סוויפט_סוזוקי</td>\n",
       "      <td>Fall</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>טויוטה</td>\n",
       "      <td>2016</td>\n",
       "      <td>אוריס</td>\n",
       "      <td>1</td>\n",
       "      <td>טיפטרוניק</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>בנזין</td>\n",
       "      <td>פרטית</td>\n",
       "      <td>פרטית</td>\n",
       "      <td>נס ציונה - רחובות</td>\n",
       "      <td>רחובות</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>אפור מטאלי</td>\n",
       "      <td>27300.0</td>\n",
       "      <td>אוריס_טויוטה</td>\n",
       "      <td>Spring</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>קיה</td>\n",
       "      <td>2012</td>\n",
       "      <td>פיקנטו</td>\n",
       "      <td>1</td>\n",
       "      <td>אוטומטית</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>בנזין</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>ראשל\"צ והסביבה</td>\n",
       "      <td>ראשון לציון</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>פיקנטו_קיה</td>\n",
       "      <td>Summer</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  manufactor  Year   model  Hand       Gear  capacity_Engine Engine_type  \\\n",
       "0     יונדאי  2015     i35     2   אוטומטית           1600.0       בנזין   \n",
       "1      ניסאן  2018   מיקרה     1   אוטומטית           1200.0       בנזין   \n",
       "2     סוזוקי  2010  סוויפט     1   אוטומטית           1450.0       בנזין   \n",
       "3     טויוטה  2016   אוריס     1  טיפטרוניק           1600.0       בנזין   \n",
       "4        קיה  2012  פיקנטו     1   אוטומטית           1248.0       בנזין   \n",
       "\n",
       "  Prev_ownership Curr_ownership               Area         City    Price  \\\n",
       "0          פרטית          פרטית    רעננה - כפר סבא        רעננה  51000.0   \n",
       "1          פרטית          פרטית       מושבים בשרון    אבן יהודה  49000.0   \n",
       "2        Unknown        Unknown                רמת          רמת  22500.0   \n",
       "3          פרטית          פרטית  נס ציונה - רחובות       רחובות  63000.0   \n",
       "4        Unknown        Unknown     ראשל\"צ והסביבה  ראשון לציון  37000.0   \n",
       "\n",
       "   Pic_num           Color        Km Model_Manufactor  Season  Age  \\\n",
       "0      2.0  כחול כהה מטאלי  144000.0       i35_יונדאי  Summer    9   \n",
       "1      0.0       כחול בהיר   69000.0      מיקרה_ניסאן  Spring    6   \n",
       "2      1.0         Unknown  145000.0    סוויפט_סוזוקי    Fall   14   \n",
       "3      5.0      אפור מטאלי   27300.0     אוריס_טויוטה  Spring    8   \n",
       "4      1.0         Unknown   70000.0       פיקנטו_קיה  Summer   12   \n",
       "\n",
       "   Age_Hand_interaction  \n",
       "0                    18  \n",
       "1                     6  \n",
       "2                    14  \n",
       "3                     8  \n",
       "4                    12  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b32fc-2b89-44ac-95d3-e440d328afed",
   "metadata": {},
   "source": [
    "\n",
    "**After preprocessing, the dataset was refined to 1485 rows from an initial 1500, demonstrating improved data quality achieved through effective outlier handling and preparation steps, ensuring retention of valuable data points.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98cfcbbb-6bc7-4abc-b0cf-e8fa561cfdaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define columns\n",
    "cat_columns = ['manufactor', 'model', 'Gear', 'Engine_type', 'Area', 'City', 'Color', 'Prev_ownership', 'Curr_ownership','Model_Manufactor']\n",
    "numeric_columns = ['capacity_Engine', 'Km', 'Pic_num', 'Year', 'Hand', 'Age', 'Age_Hand_interaction']\n",
    "\n",
    "\n",
    "X = prepared_df.drop(columns=['Price'])\n",
    "y = prepared_df['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73035b4e-5a4a-4940-8dd8-4e3feaf57c55",
   "metadata": {},
   "source": [
    "#### Defining Categorical and Numeric Columns\n",
    "\n",
    "Defining `cat_columns` and `numeric_columns` before splitting ensures consistent preprocessing for both training and test sets, preserving feature engineering integrity.\n",
    "\n",
    "#### Train-Test Split\n",
    "\n",
    "- **`test_size=0.2`**: Uses 20% of the data for testing, balancing between sufficient training data and a reliable test set.\n",
    "- **`random_state=42`**: Ensures reproducibility, with `42` being a common choice for consistency across runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33021fab-11a6-4f49-9f8e-0844d0de753b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_columns),\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), cat_columns)\n",
    "    ])\n",
    "\n",
    "# Fit and transform the data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Get feature names\n",
    "feature_names_cat = []\n",
    "for i, col in enumerate(cat_columns):\n",
    "    feature_names_cat.extend([f\"{col}_{val}\" for val in preprocessor.named_transformers_['cat'].categories_[i]])\n",
    "feature_names = numeric_columns + feature_names_cat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df0b3a6-de42-4a38-a2ce-5a900bf8ce0d",
   "metadata": {},
   "source": [
    "#### Defining the Preprocessor\n",
    "\n",
    "The `preprocessor` is defined to apply different transformations to numeric and categorical columns, ensuring the data is standardized and properly encoded for the model.\n",
    "\n",
    "#### Fitting and Transforming the Data\n",
    "\n",
    "- **`X_train_transformed` and `X_test_transformed`**: The preprocessor is fitted on the training data and then applied to both training and test sets, maintaining consistency in preprocessing.\n",
    "\n",
    "#### Generating Feature Names\n",
    "\n",
    "- **`feature_names_cat`**: Extracts and formats the feature names for the encoded categorical variables, combining them with the numeric feature names for a complete list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0325ec83-8cb1-4fd4-8f84-7228c6d2c895",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = ElasticNet(random_state=42)\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 1.5],\n",
    "    'l1_ratio': [0.3, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV to find best parameters\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Use best parameters to evaluate model using cross-validation on training set\n",
    "best_model = grid_search.best_estimator_\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(best_model, X_train_transformed, y_train, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ce873-3975-4f0a-88fa-717965808c86",
   "metadata": {},
   "source": [
    "#### Parameter Grid for GridSearchCV\n",
    "\n",
    "- **`param_grid`**: Specifies the range of hyperparameters (`alpha` and `l1_ratio`) to search for optimal values. Hyperparameters are parameters whose values are set before the learning process begins and control the model's learning process.\n",
    "\n",
    "#### Performing GridSearchCV\n",
    "\n",
    "- **`grid_search`**: Uses 10-fold cross-validation to find the best hyperparameters, optimizing for negative mean squared error.\n",
    "\n",
    "  - **`scoring='neg_mean_squared_error'`**: This scoring method evaluates models based on the negative mean squared error, with lower values indicating better model performance.\n",
    "  - **`n_jobs=-1`**: Utilizes all available CPU cores for parallel processing, speeding up the computation.\n",
    "\n",
    "#### Evaluating the Model\n",
    "\n",
    "- **`best_model`**: The best estimator from `GridSearchCV`.\n",
    "- **`cross_val_score`**: Evaluates the model using 10-fold cross-validation on the training set to ensure robust performance metrics.\n",
    "\n",
    "  - **`KFold(n_splits=10, shuffle=True, random_state=42)`**: Splits the data into 10 folds for cross-validation, shuffling the data to ensure randomness and setting a seed for reproducibility.\n",
    "  \n",
    "\n",
    "\n",
    "This code optimizes an ElasticNet model through GridSearchCV for hyperparameter tuning and K-Fold cross-validation for performance assessment, aiming to balance bias and variance, reduce overfitting, and ensure robust performance on unseen data by systematically exploring combinations of alpha and l1_ratio to find the best model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0473733c-9405-4684-824a-9b4ae144a213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit model on training data using best parameters\n",
    "best_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test_transformed)\n",
    "mse = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97c04398-dde9-4372-9ffa-0a0c8b6a3073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate permutation importance using training set\n",
    "importance = permutation_importance(best_model, X_train_transformed, y_train, n_repeats=10, random_state=42)\n",
    "feature_importances = importance.importances_mean\n",
    "\n",
    "# Create a dictionary for permutation importance\n",
    "importance_dict = dict(zip(feature_names, feature_importances))\n",
    "sorted_importances = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Get model coefficients\n",
    "coefficients = best_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b57c06-30f1-48bf-8e1a-13c519f8cbfc",
   "metadata": {},
   "source": [
    "This code calculates permutation importance and extracts model coefficients to identify influential features. Permutation importance measures each feature's impact on model performance by randomly shuffling its values and observing the resulting change in model error. Model coefficients indicate feature weights in the ElasticNet model. Together, these methods provide complementary insights into feature relevance, aiding in model interpretation and potential feature selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22da4943-b066-4c51-a661-fdca57db30d1",
   "metadata": {},
   "source": [
    "## Resultes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d847f2da-dd90-4bc0-a7d7-3c7b071af3dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE: 11056.732\n",
      "\n",
      "Top 5 most influential features:\n",
      "Age_Hand_interaction: 0.433, Coefficient = 10142.112 (positive impact)\n",
      "Year: 0.387, Coefficient = 9675.055 (positive impact)\n",
      "Age: 0.386, Coefficient = -9663.456 (negative impact)\n",
      "Hand: 0.203, Coefficient = -7016.061 (negative impact)\n",
      "capacity_Engine: 0.029, Coefficient = 2543.873 (positive impact)\n"
     ]
    }
   ],
   "source": [
    "print(f'The RMSE: {np.sqrt(mse):.3f}')\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "# Print top 5 most influential features with scaled permutation importance\n",
    "print(\"\\nTop 5 most influential features:\")\n",
    "for feature, importance_value in sorted_importances[:5]:\n",
    "    coefficient_index = feature_names.index(feature)\n",
    "    coefficient_value = coefficients[coefficient_index]\n",
    "    sign = \"positive\" if coefficient_value > 0 else \"negative\"\n",
    "    print(f\"{feature}: {importance_value:.3f}, Coefficient = {coefficient_value:.3f} ({sign} impact)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d760f7c1-e115-46f6-bdb4-8b0edf17684d",
   "metadata": {},
   "source": [
    "---\n",
    "The RMSE (Root Mean Squared Error) measures the average prediction error of the model, calculated here as 11056.73. Lower RMSE values indicate better model accuracy. RMSE value of 11490.55 indicates solid predictive accuracy for estimating car prices.\n",
    "\n",
    "Top 5 Influential Features:\n",
    "- **Age_Hand_interaction**: Positive impact (importance: 0.4328, Coefficient: 10142.1121). Indicates higher car prices with increased interaction between age and hand.\n",
    "- **Year**: Negative impact (importance: 0.3866, Coefficient: 9675.0553). Suggests lower prices for cars with fewer previous owners.\n",
    "- **Age**: Positive impact (importance: 0.3857, Coefficient: -9663.4561). Newer cars tend to have higher predicted prices.\n",
    "- **Hand**: Negative impact (importance: 0.2027, Coefficient: -7016.0609). Older cars generally predict lower prices.\n",
    "- **capacity_Engine**: Negative impact (Coefficient: 0.0286, Coefficient: 2543.8732). Higher mileage correlates with lower predicted prices.\n",
    "\n",
    "These insights help understand how each feature influences car price predictions in the model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
